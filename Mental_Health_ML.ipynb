{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mental_Health_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdCpxD2BwTxW",
        "outputId": "e3cd6cb9-1210-4b14-bb37-92c8512facc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Import relevant modules\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "fLphIV3vCHpa",
        "outputId": "fbaea0be-2fd8-4876-e863-81644e307946"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported modules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Import Stopwords\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "en_stop_words = stopwords.words('english')\n",
        "print(en_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "gMWmm7gTwKf1",
        "outputId": "84815b2b-3a69-4350-c6a2-4e10bc68cfeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Set Top Level Variables\n",
        "vocab_size = 5000  # Only consider the top 5K words\n",
        "max_length = 50 # Maximum question (text) size in words\n",
        "embedding_dim = 64"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e7GFMnxTv7EC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Import data\n",
        "DF1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/counselchat-data.csv')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LNnooNtrCfn8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Task: Create new topics column by picking only first value out of multiple comma separated mental problems.\n",
        "DF1['first_topics'] = DF1['topics'].apply(lambda n: str(n).split(',')[0])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yiykh-zfwZQe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Show first 5 examples from dataframe\n",
        "DF1[['questionText', 'first_topics']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "rJat-AiQxE41",
        "outputId": "44f789e9-9165-4946-eb2d-73c7b49011ea"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        questionText       first_topics\n",
              "0  My wife and mother are having tense disagreeme...    Family Conflict\n",
              "1  I'm planning to have baby, so I have to quit s...    Substance Abuse\n",
              "2  I have secrets in my mind, and I don't know wh...    Family Conflict\n",
              "3  I am extremely possessive in my relationships ...  Behavioral Change\n",
              "4  I had a head injury a few years ago and my min...            Anxiety"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65b1066d-5d99-4eb5-8c78-512bde2f2a6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionText</th>\n",
              "      <th>first_topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife and mother are having tense disagreeme...</td>\n",
              "      <td>Family Conflict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm planning to have baby, so I have to quit s...</td>\n",
              "      <td>Substance Abuse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have secrets in my mind, and I don't know wh...</td>\n",
              "      <td>Family Conflict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am extremely possessive in my relationships ...</td>\n",
              "      <td>Behavioral Change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I had a head injury a few years ago and my min...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65b1066d-5d99-4eb5-8c78-512bde2f2a6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65b1066d-5d99-4eb5-8c78-512bde2f2a6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65b1066d-5d99-4eb5-8c78-512bde2f2a6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Number of Unique Topics \n",
        "DF1.first_topics.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "mcrDKC67wlPP",
        "outputId": "34a7cfa9-f2f1-467c-c274-843376f131df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Remove Stopwords\n",
        "DF1['questionText_removed_stopwords'] = DF1['questionText'].apply(lambda x: ' '.join([word for word in str(x).split(' ') if word not in (en_stop_words)]))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f7Km2mA1x_pN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Show first 5 examples from dataframe (new question text and topics columns)\n",
        "DF1[['questionText_removed_stopwords', 'first_topics']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "cellView": "form",
        "id": "3rPOjapTzodU",
        "outputId": "c7600e66-2be5-4aba-aa0d-1b896e3d1179"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      questionText_removed_stopwords       first_topics\n",
              "0  My wife mother tense disagreements. In past, t...    Family Conflict\n",
              "1  I'm planning baby, I quit smoking - hard. Some...    Substance Abuse\n",
              "2  I secrets mind, I know them. I want tell wife ...    Family Conflict\n",
              "3  I extremely possessive relationships hurting f...  Behavioral Change\n",
              "4  I head injury years ago mind races time. I tro...            Anxiety"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a43068c-2798-4a29-b0d9-df2713c79a95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionText_removed_stopwords</th>\n",
              "      <th>first_topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife mother tense disagreements. In past, t...</td>\n",
              "      <td>Family Conflict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm planning baby, I quit smoking - hard. Some...</td>\n",
              "      <td>Substance Abuse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I secrets mind, I know them. I want tell wife ...</td>\n",
              "      <td>Family Conflict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I extremely possessive relationships hurting f...</td>\n",
              "      <td>Behavioral Change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I head injury years ago mind races time. I tro...</td>\n",
              "      <td>Anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a43068c-2798-4a29-b0d9-df2713c79a95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a43068c-2798-4a29-b0d9-df2713c79a95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a43068c-2798-4a29-b0d9-df2713c79a95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Drop Null and create new DF -  ds\n",
        "ds = DF1[['questionText_removed_stopwords', 'first_topics']].dropna()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "spjOEw0izENM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Number of Unique Topics \n",
        "ds.first_topics.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "LDealrGX0wuc",
        "outputId": "7381f5f1-d610-46af-940b-92f18d621a38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CREATE A TENSORFLOW DATA PIPELINE FOR TEXT PREPROCESSING & VECTORIZATION"
      ],
      "metadata": {
        "id": "e5-Kv4lVF0aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Convert Topics From Strings to Integers\n",
        "ds[\"first_topics\"] = ds[\"first_topics\"].astype('category')\n",
        "ds[\"first_topics_id\"] = ds[\"first_topics\"].cat.codes\n",
        "ds.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "cellView": "form",
        "id": "OK5UltYI1qYs",
        "outputId": "c2d77aec-b065-482b-c8a9-e521dd8545c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      questionText_removed_stopwords       first_topics  \\\n",
              "0  My wife mother tense disagreements. In past, t...    Family Conflict   \n",
              "1  I'm planning baby, I quit smoking - hard. Some...    Substance Abuse   \n",
              "2  I secrets mind, I know them. I want tell wife ...    Family Conflict   \n",
              "3  I extremely possessive relationships hurting f...  Behavioral Change   \n",
              "4  I head injury years ago mind races time. I tro...            Anxiety   \n",
              "\n",
              "   first_topics_id  \n",
              "0               12  \n",
              "1               29  \n",
              "2               12  \n",
              "3                4  \n",
              "4                3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e9308f0-9afa-4a4b-9394-941347e941e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questionText_removed_stopwords</th>\n",
              "      <th>first_topics</th>\n",
              "      <th>first_topics_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife mother tense disagreements. In past, t...</td>\n",
              "      <td>Family Conflict</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm planning baby, I quit smoking - hard. Some...</td>\n",
              "      <td>Substance Abuse</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I secrets mind, I know them. I want tell wife ...</td>\n",
              "      <td>Family Conflict</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I extremely possessive relationships hurting f...</td>\n",
              "      <td>Behavioral Change</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I head injury years ago mind races time. I tro...</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e9308f0-9afa-4a4b-9394-941347e941e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e9308f0-9afa-4a4b-9394-941347e941e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e9308f0-9afa-4a4b-9394-941347e941e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Build a Dictionary for id to text category (topic) look-up:\n",
        "id_to_topics = pd.Series(ds.first_topics.values,index=ds.first_topics_id).to_dict()\n",
        "id_to_topics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-cxois9E0sxE",
        "outputId": "5ee13057-1261-4203-d58c-dcfe831b1963"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Addiction',\n",
              " 1: \"Alzheimer's\",\n",
              " 2: 'Anger Management',\n",
              " 3: 'Anxiety',\n",
              " 4: 'Behavioral Change',\n",
              " 5: 'Career Counseling',\n",
              " 6: 'Children & Adolescents',\n",
              " 7: 'Counseling Fundamentals ',\n",
              " 8: 'Depression',\n",
              " 9: 'Diagnosis',\n",
              " 10: 'Domestic Violence',\n",
              " 11: 'Eating Disorders',\n",
              " 12: 'Family Conflict',\n",
              " 13: 'Grief and Loss',\n",
              " 14: 'Human Sexuality',\n",
              " 15: 'Intimacy',\n",
              " 16: 'LGBTQ',\n",
              " 17: 'Legal & Regulatory',\n",
              " 18: 'Marriage',\n",
              " 19: 'Military Issues ',\n",
              " 20: 'Parenting',\n",
              " 21: 'Professional Ethics',\n",
              " 22: 'Relationship Dissolution ',\n",
              " 23: 'Relationships',\n",
              " 24: 'Self-esteem',\n",
              " 25: 'Sleep Improvement',\n",
              " 26: 'Social Relationships',\n",
              " 27: 'Spirituality',\n",
              " 28: 'Stress',\n",
              " 29: 'Substance Abuse',\n",
              " 30: 'Trauma',\n",
              " 31: 'Workplace Relationships',\n",
              " 32: 'nan'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Store look-up dictionary as pickle file\n",
        "import pickle\n",
        "pkl_file = open(\"id_to_topics.pkl\", \"wb\")\n",
        "pickle.dump(id_to_topics, pkl_file)\n",
        "pkl_file.close()\n",
        "\n",
        "pkl_file = open(\"id_to_topics.pkl\", \"rb\")\n",
        "uploaded_id_to_topics = pickle.load(pkl_file)\n",
        "print(uploaded_id_to_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "Hmrh2HQ-1QJz",
        "outputId": "49da38c9-7758-4709-f984-c95f607c2dc8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{12: 'Family Conflict', 29: 'Substance Abuse', 4: 'Behavioral Change', 3: 'Anxiety', 22: 'Relationship Dissolution ', 2: 'Anger Management', 25: 'Sleep Improvement', 21: 'Professional Ethics', 26: 'Social Relationships', 23: 'Relationships', 18: 'Marriage', 10: 'Domestic Violence', 14: 'Human Sexuality', 19: 'Military Issues ', 8: 'Depression', 13: 'Grief and Loss', 30: 'Trauma', 15: 'Intimacy', 31: 'Workplace Relationships', 16: 'LGBTQ', 27: 'Spirituality', 24: 'Self-esteem', 20: 'Parenting', 32: 'nan', 11: 'Eating Disorders', 17: 'Legal & Regulatory', 5: 'Career Counseling', 0: 'Addiction', 28: 'Stress', 9: 'Diagnosis', 1: \"Alzheimer's\", 7: 'Counseling Fundamentals ', 6: 'Children & Adolescents'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Limit the number of samples to be used in testing the pipeline\n",
        "# data_size= 1200 #instead of 431306 \n",
        "data= ds #[:data_size]\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "R2ltlwaK2Gv8",
        "outputId": "7cebbb27-ee62-41c1-a4a2-d34a1755ea4f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1482 entries, 0 to 1481\n",
            "Data columns (total 3 columns):\n",
            " #   Column                          Non-Null Count  Dtype   \n",
            "---  ------                          --------------  -----   \n",
            " 0   questionText_removed_stopwords  1482 non-null   object  \n",
            " 1   first_topics                    1482 non-null   category\n",
            " 2   first_topics_id                 1482 non-null   int8    \n",
            "dtypes: category(1), int8(1), object(1)\n",
            "memory usage: 27.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi9M0p5K2LWP",
        "outputId": "bf467748-e36f-4162-ba82-49a1a4689cff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1482, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Split the Raw Dataset into Train and Test Datasets\n",
        "\n",
        "#save features and targets from the 'data'\n",
        "features, targets = data['questionText_removed_stopwords'], data['first_topics_id']\n",
        "\n",
        "train_features, test_features, train_targets, test_targets = train_test_split(\n",
        "        features, targets,\n",
        "        train_size=0.8,\n",
        "        test_size=0.2,\n",
        "        random_state=40,\n",
        "        shuffle = True\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XHMdBavO2Nyq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  6. Prepare TensorFlow Datasets from Pandas DF\n",
        "\n",
        "#We convert the data stored in Pandas Data Frame into  a data stored in TensorFlow Data Set as below:\n",
        "\n",
        "# train X & y\n",
        "train_text_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(train_features.values, tf.string)\n",
        ") \n",
        "train_cat_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(train_targets.values, tf.int64),\n",
        "\n",
        ") \n",
        "# test X & y\n",
        "test_text_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(test_features.values, tf.string)\n",
        ") \n",
        "test_cat_ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "            tf.cast(test_targets.values, tf.int64),\n",
        "\n",
        ") "
      ],
      "metadata": {
        "cellView": "form",
        "id": "UGKkZAH02R9l"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USE KERAS TEXT VECTORIZATION LAYER**"
      ],
      "metadata": {
        "id": "ziP32HDOH6LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. PREPROCESS THE TEXT WITH THE KERAS `TEXTVECTORIZATION` LAYER"
      ],
      "metadata": {
        "id": "H2WnjsLQIFsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 8.1. Define your own `custom_standardization` function\n",
        "First, I define a function which will preprocess the given text.\n",
        "The `custom_standardization` function will convert the given string to a standart form by transforming the input applying several updates:\n",
        "* convert all characters to lowercase\n",
        "* remove special symbols, extra spaces, html tags, digits, and puctuations\n",
        "* remove stop words"
      ],
      "metadata": {
        "id": "rOqkPsQIILkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "def custom_standardization(input_string):\n",
        "    \"\"\" Remove html line-break tags and handle punctuation \"\"\"\n",
        "    for each in en_stop_words:\n",
        "      if each == 'not' or each == 'no' or each == 'never' : \n",
        "        input_string = input_string\n",
        "      else:\n",
        "        input_string = tf.strings.regex_replace(input_string, ' '+each+' ' , r\" \")\n",
        "    no_uppercased = tf.strings.lower(input_string, encoding='utf-8')\n",
        "    no_punctuations = tf.strings.regex_replace(no_uppercased, f\"([{string.punctuation}])\", r\" \")\n",
        "    no_extra_space = tf.strings.regex_replace(no_punctuations, \" +\",\" \")\n",
        "\n",
        "    return no_extra_space"
      ],
      "metadata": {
        "id": "x5FHIx5-3dGG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. Configure the Keras `TextVectorization layer`"
      ],
      "metadata": {
        "id": "HZwekdGaIivb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preprocess the text, I will use the Keras `TextVectorization` layer. \n",
        "\n",
        "```python\n",
        "tf.keras.layers.TextVectorization(\n",
        "    max_tokens=None,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"whitespace\",\n",
        "    ngrams=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=None,\n",
        "    pad_to_max_tokens=False,\n",
        "    vocabulary=None,\n",
        "    **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "The Keras `TextVectorization` layer processes each example in the dataset as follows:\n",
        "\n",
        "1. Standardize each example (usually lowercasing + punctuation stripping)\n",
        "\n",
        "2. Split each example into substrings (usually words)\n",
        "\n",
        "3. Recombine substrings into tokens (usually ngrams)\n",
        "\n",
        "4. Index tokens (associate a unique int value with each token)\n",
        "\n",
        "5. Transform each example using this index, either into a vector of ints or a dense float vector.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOkYf7pqIy4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build our `TextVectorization` layer by providing:\n",
        "\n",
        "1. The `custom_standardization()` function for the `standardize` method (callable).\n",
        "2. The `vocab_size` as the `max_tokens` number: The `max_tokens` is the maximum size of the vocabulary that will be created from the dataset. If `None`, there is no cap on the size of the vocabulary. Note that this vocabulary contains 1 **OOV (Out Of Vocabulary)** token, so the effective number of tokens is (max_tokens - 1 - (1 if output_mode == \"int\" else 0)).\n",
        "3. The `int` keyword as the `output_mode`: Optional specification for the **output** of the layer. Values can be \n",
        "* \"**int**\", \n",
        "* \"**multi_hot**\", \n",
        "* \"**count**\" or \n",
        "* \"**tf_idf**\", \n",
        "\n",
        "Configuring the layer as follows: \n",
        "* \"**int**\": Outputs integer indices, one integer index per split string token. When output_mode == \"int\", 0 is reserved for masked locations; this reduces the vocab size to max_tokens - 2 instead of max_tokens - 1.\n",
        "\n",
        "* \"**multi_hot**\": Outputs a single int array per batch, of either vocab_size or max_tokens size, containing 1s in all elements where the token mapped to that index exists at least once in the batch item. \n",
        "\n",
        "* \"**count**\": Like \"multi_hot\", but the int array contains a count of the number of times the token at that index appeared in the batch item. \n",
        "\n",
        "* \"**tf_idf**\": Like \"multi_hot\", but the TF-IDF algorithm is applied to find the value in each token slot. \n",
        "\n",
        "For \"**int**\" output, any shape of input and output is supported. \n",
        "\n",
        "For **all other output modes**, currently only **rank 1 inputs** (and rank 2 outputs after splitting) are supported. \n"
      ],
      "metadata": {
        "id": "YRxswXnfJLmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GPUKaHdi2c9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Create a vectorization layer and adapt it to the text\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size+2,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(ds['questionText_removed_stopwords'])\n",
        "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iO1YKtZ621MX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test Vectorization\n",
        "input_string = \"I'm in my early 20s. I’ve been married once, and he cheated on me. Ever since then, I've felt ugly no matter what. I'm engaged, and I still feel ugly. I don't like to take pictures of myself\"\n",
        "print(\"input:  \", input_string)\n",
        "output_string= custom_standardization(input_string)\n",
        "print(\"output: \", output_string.numpy().decode(\"utf-8\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3sCHi4Y3h4E",
        "outputId": "1d2649e1-9aa8-4bd0-ca66-0e55056d484f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:   I'm in my early 20s. I’ve been married once, and he cheated on me. Ever since then, I've felt ugly no matter what. I'm engaged, and I still feel ugly. I don't like to take pictures of myself\n",
            "output:  i m early 20s i’ve married once cheated me ever since then i ve felt ugly no matter what i m engaged i still feel ugly i like take pictures myself\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3. Adapt the Keras `TextVectorization` layer with the **training** data set, (not test data set!) "
      ],
      "metadata": {
        "id": "90y-cU8NJvEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Adapt to trainset features and get vocabulary\n",
        "vectorize_layer.adapt(train_features)\n",
        "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices"
      ],
      "metadata": {
        "id": "zhr08YSH3lAK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print few samples\n",
        "\n",
        "print(\"vocab has the \", len(vocab),\" entries\")\n",
        "print(\"vocab has the following first 10 entries\")\n",
        "for word in range(10):\n",
        "  print(word, \" represents the word: \", vocab[word])\n",
        "\n",
        "for X in train_features[:2]:\n",
        "  print(\" Given raw data: \" )\n",
        "  print(X)\n",
        "  tokenized = vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers: \" )\n",
        "  print (tokenized)\n",
        "  print(\" Text after Tokenized and Transformed: \")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ vocab[each]\n",
        "  print(transformed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "htjRKsif4ENJ",
        "outputId": "8244edb9-5f3a-44c5-db14-ec91e95cc9d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab has the  3266  entries\n",
            "vocab has the following first 10 entries\n",
            "0  represents the word:  \n",
            "1  represents the word:  [UNK]\n",
            "2  represents the word:  i\n",
            "3  represents the word:  m\n",
            "4  represents the word:  he\n",
            "5  represents the word:  feel\n",
            "6  represents the word:  like\n",
            "7  represents the word:  it\n",
            "8  represents the word:  me\n",
            "9  represents the word:  my\n",
            " Given raw data: \n",
            "I early 20s I still live parents I can't afford live alone.\r\n",
            "\r\n",
            "My mother says I live roof I follow rules. She trying control life. What I do?\n",
            " Tokenized and Transformed to a vector of integers: \n",
            "tf.Tensor(\n",
            "[[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            "  881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
            " Text after Tokenized and Transformed: \n",
            " i early 20s i still live parents i can t afford live alone my mother says i live roof i follow rules she trying control life what i do                     \n",
            " Given raw data: \n",
            "It 20 years ago, pain resurfaced I started seeing Facebook posts great life is. I feel angry. How I handle this?\n",
            " Tokenized and Transformed to a vector of integers: \n",
            "tf.Tensor(\n",
            "[[   7  624   17   78  389 1162    2   91  235  814 1012  200   31   50\n",
            "     2    5  167   18    2  241   23    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]], shape=(1, 50), dtype=int64)\n",
            " Text after Tokenized and Transformed: \n",
            " it 20 years ago pain resurfaced i started seeing facebook posts great life is i feel angry how i handle this                             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.4. Save & Upload TextVectorization layer"
      ],
      "metadata": {
        "id": "a68aHX-hKLhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the facts that adapting the Keras `TextVectorization` layer on a large text dataset takes considerable amount of time and porting the adapted layer to a different deployment environment is a high possibility, it is good to know how to save and load it.\n",
        "\n",
        "How to save a Keras `TextVectorization` layer? \n",
        "\n",
        "[There are currently 2 ways of doing it](https://stackoverflow.com/questions/65103526/how-to-save-textvectorization-to-disk-in-tensorflow):\n",
        "* save the Keras `TextVectorization` layer in a Keras Model\n",
        "* save the Keras `TextVectorization` layer as a pickle file.\n",
        "\n",
        "In this tutorial, I will use the first approach as it is native to the TF/Keras environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "BHUHwktXKQpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4.1. Create a temporary Keras `model` by adding the adapted Keras `TextVectorization` layer"
      ],
      "metadata": {
        "id": "eDkFPD5CKhUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create model.\n",
        "vectorize_layer_model = tf.keras.models.Sequential()\n",
        "vectorize_layer_model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "vectorize_layer_model.add(vectorize_layer)\n",
        "vectorize_layer_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaCmqeQ4GSO",
        "outputId": "cdadf40b-f1a1-4d9a-aefc-3cda78f60476"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.4.2. Save the temporary model including the adapted Keras `TextVectorization` layer"
      ],
      "metadata": {
        "id": "U6bVnelPKv9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"vectorize_layer_model\""
      ],
      "metadata": {
        "id": "ZWKCxZ1s4X66"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save model\n",
        "vectorize_layer_model.save(filepath, save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "vvItql_O4aPN",
        "outputId": "0cd4e4ce-01af-4c02-9730-75ed61803c90"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: vectorize_layer_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.4.3. Load the `vectorize_layer_model` back to chek if saving is succesfull"
      ],
      "metadata": {
        "id": "EWJLKXh8K6Sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load model\n",
        "loaded_vectorize_layer_model = tf.keras.models.load_model(filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyKTbu7p4b1f",
        "outputId": "41aff87e-a79a-4b60-f5e6-52b52d24fd01"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4.4 Retrieve the **loaded** Keras `TextVectorization` layer\n",
        "\n",
        "Here, you have 2 options:\n",
        "* use the `loaded_model.predicted()` method to use the Keras `TextVectorization` layer, or\n",
        "* get the Keras `TextVectorization` layer out of the `loaded_model` as below:\n",
        "\n"
      ],
      "metadata": {
        "id": "TWFBCkdELGbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retrieve Model\n",
        "loaded_vectorize_layer = loaded_vectorize_layer_model.layers[0]\n"
      ],
      "metadata": {
        "id": "lIiI218B4gGs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4.5. Compare the original and loaded `TextVectorization` layers"
      ],
      "metadata": {
        "id": "x09KJ7oXLKb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_vocab=loaded_vectorize_layer.get_vocabulary()\n",
        "print(\"original vocab has the \", len(vocab),\" entries\")\n",
        "print(\"loaded vocab has the   \", len(loaded_vocab),\" entries\")\n",
        "print(\"loaded vocab has the following first 10 entries\")\n",
        "for word in range(10):\n",
        "  print(word, \" represents the word: \")\n",
        "  print(vocab[word], \" in original vocab\")\n",
        "  print(loaded_vocab[word], \" in loaded vocab\")\n",
        "for X in train_features[:1]:\n",
        "  print(\" Given raw data: \" )\n",
        "  print(X)\n",
        "\n",
        "  tokenized = vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the original vectorize layer:\" )\n",
        "  print (tokenized)\n",
        "\n",
        "  tokenized = loaded_vectorize_layer(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the loaded vectorize layer:\" )\n",
        "  print (tokenized)\n",
        "  \n",
        "  tokenized = loaded_vectorize_layer_model.predict(tf.expand_dims(X, -1))\n",
        "  print(\" Tokenized and Transformed to a vector of integers by the loaded_vectorize_layer_model:\" )\n",
        "  print (tokenized)\n",
        "\n",
        "  print(\" Text after Tokenized and Transformed by the original vectorize layer:: \")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ vocab[each]\n",
        "  print(transformed)\n",
        "\n",
        "  print(\" Text after Tokenized and Transformed by the loaded vectorize layer:\")\n",
        "  transformed = \"\"\n",
        "  for each in tf.squeeze(tokenized):\n",
        "    transformed= transformed+ \" \"+ loaded_vocab[each]\n",
        "  print(transformed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkrnWe1Y4xSp",
        "outputId": "37b25d5b-6a1d-458a-fb07-e538bfbd10c2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original vocab has the  3266  entries\n",
            "loaded vocab has the    3266  entries\n",
            "loaded vocab has the following first 10 entries\n",
            "0  represents the word: \n",
            "  in original vocab\n",
            "  in loaded vocab\n",
            "1  represents the word: \n",
            "[UNK]  in original vocab\n",
            "[UNK]  in loaded vocab\n",
            "2  represents the word: \n",
            "i  in original vocab\n",
            "i  in loaded vocab\n",
            "3  represents the word: \n",
            "m  in original vocab\n",
            "m  in loaded vocab\n",
            "4  represents the word: \n",
            "he  in original vocab\n",
            "he  in loaded vocab\n",
            "5  represents the word: \n",
            "feel  in original vocab\n",
            "feel  in loaded vocab\n",
            "6  represents the word: \n",
            "like  in original vocab\n",
            "like  in loaded vocab\n",
            "7  represents the word: \n",
            "it  in original vocab\n",
            "it  in loaded vocab\n",
            "8  represents the word: \n",
            "me  in original vocab\n",
            "me  in loaded vocab\n",
            "9  represents the word: \n",
            "my  in original vocab\n",
            "my  in loaded vocab\n",
            " Given raw data: \n",
            "I early 20s I still live parents I can't afford live alone.\r\n",
            "\r\n",
            "My mother says I live roof I follow rules. She trying control life. What I do?\n",
            " Tokenized and Transformed to a vector of integers by the original vectorize layer:\n",
            "tf.Tensor(\n",
            "[[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            "  881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
            " Tokenized and Transformed to a vector of integers by the loaded vectorize layer:\n",
            "tf.Tensor(\n",
            "[[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            "  881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]], shape=(1, 50), dtype=int64)\n",
            " Tokenized and Transformed to a vector of integers by the loaded_vectorize_layer_model:\n",
            "[[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            "  881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            " Text after Tokenized and Transformed by the original vectorize layer:: \n",
            " i early 20s i still live parents i can t afford live alone my mother says i live roof i follow rules she trying control life what i do                     \n",
            " Text after Tokenized and Transformed by the loaded vectorize layer:\n",
            " i early 20s i still live parents i can t afford live alone my mother says i live roof i follow rules she trying control life what i do                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, we succesfully saved and loaded the *adapted* Keras `TextVectorization` layer!\n",
        "\n",
        "We can continue to the TensorFlow datapipeline with the **adapted** Keras `TextVectorization` layer:"
      ],
      "metadata": {
        "id": "kAte6FXJLdMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. APPLY KERAS `TEXTVECTORIZATION` TO TRAIN & TEST DATA SETS \n",
        "\n",
        "We can define a function to apply the Keras `TextVectorization` on a given string as follows:"
      ],
      "metadata": {
        "id": "D4gSvYjzLglc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text_input(sample):\n",
        "    text = sample\n",
        "    text = tf.expand_dims(text, -1)  \n",
        "    #return tf.squeeze(vectorize_layer(text))\n",
        "    return tf.squeeze(loaded_vectorize_layer(text)) "
      ],
      "metadata": {
        "id": "taBJ-NUU4zjb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the TensorFlow `tf.data` API (TF Data Pipeline) `map()` funtion to apply `convert_text_input()` on every sample in the `text` column (reviews) of the training dataset."
      ],
      "metadata": {
        "id": "sJXm8c-oL0va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train X\n",
        "train_text_ds = train_text_ds_raw.map(convert_text_input, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "# Test X\n",
        "test_text_ds = test_text_ds_raw.map(convert_text_input, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "3pVz-oNN430j"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the converted/encoded questiontexts"
      ],
      "metadata": {
        "id": "N0H0M8sJL26K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for each in train_text_ds.take(3):\n",
        "  print(each)"
      ],
      "metadata": {
        "id": "52SbH8HhL71d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for each in train_text_ds.take(3):\n",
        "  print(each)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOYWiB45jJ",
        "outputId": "3a177a96-34f7-4999-ff25-470e08d0f94c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            " 881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   7  624   17   78  389 1162    2   91  235  814 1012  200   31   50\n",
            "    2    5  167   18    2  241   23    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0], shape=(50,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 18 140 158 127 309   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10. GENERATE THE TRAIN SET BY COMBINING X & Y:\n",
        "* **X**: the preprocessed & encoded reviews \n",
        "* **y**: encoded categories) "
      ],
      "metadata": {
        "id": "Trwx8yzEMO5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.zip(\n",
        "    (\n",
        "            train_text_ds,\n",
        "            train_cat_ds_raw\n",
        "     )\n",
        ") "
      ],
      "metadata": {
        "id": "7Z5ehdSvMB8D"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.data.Dataset.zip(\n",
        "    (\n",
        "            test_text_ds,\n",
        "            test_cat_ds_raw\n",
        "     )\n",
        ") "
      ],
      "metadata": {
        "id": "tu-s07eQ4-7J"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the result of the **Text Vectorization** in the **Data Pipelining** as follows:\n"
      ],
      "metadata": {
        "id": "fUvVQcTjMlPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in train_ds.take(1):\n",
        "  print(\"input (review) X.shape: \", X.shape)\n",
        "  print(\"output (category) y.shape: \", y.shape)\n",
        "  print(\"input (review) X: \", X)\n",
        "  print(\"output (category) y: \",y)\n",
        "  input = \" \".join([vocab[_] for _ in np.squeeze(X)])\n",
        "  output = id_to_topics[y.numpy()]\n",
        "  print(\"X: input (review) in text: \" , input)\n",
        "  print(\"y: output (category) in text: \" , output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRbMpoSH5Arv",
        "outputId": "bcba086c-80f3-47a8-b916-a2c5821c393a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input (review) X.shape:  (50,)\n",
            "output (category) y.shape:  ()\n",
            "input (review) X:  tf.Tensor(\n",
            "[  2 297 207   2  30 100  95   2  25  28 470 100 154   9 129  84   2 100\n",
            " 881   2 727 880  19 149 301  31  46   2  39   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
            "output (category) y:  tf.Tensor(12, shape=(), dtype=int64)\n",
            "X: input (review) in text:  i early 20s i still live parents i can t afford live alone my mother says i live roof i follow rules she trying control life what i do                     \n",
            "y: output (category) in text:  Family Conflict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. FINALIZE TENSORFLOW DATA PIPELINE\n",
        "Finalize TensorFlow Data Pipeline by setting necessary parameters for batching, shuffling , and optimizing as follows:\n",
        "\n"
      ],
      "metadata": {
        "id": "dhb30UcWMtMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "buffer_size= train_ds.cardinality().numpy()\n",
        "\n",
        "train_ds = train_ds.shuffle(buffer_size=buffer_size)\\\n",
        "                   .batch(batch_size=batch_size,drop_remainder=True)\\\n",
        "                   .cache()\\\n",
        "                   .prefetch(AUTOTUNE)\n",
        "\n",
        "test_ds = test_ds.shuffle(buffer_size=buffer_size)\\\n",
        "                   .batch(batch_size=batch_size,drop_remainder=True)\\\n",
        "                   .cache()\\\n",
        "                   .prefetch(AUTOTUNE)"
      ],
      "metadata": {
        "id": "O27ai9S95CbB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.element_spec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7RTQSFa5Kxe",
        "outputId": "f6816ad0-ab4b-445d-eaeb-8d271aec273e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=<unknown>, dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(64,), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILD AN END-TO-END MODEL**"
      ],
      "metadata": {
        "id": "yq3NVX3fM_Ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. CREATE MODEL"
      ],
      "metadata": {
        "id": "OZsUgeVkNHhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
        "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
        "    # Add a Dense layer with 33 units and softmax activation.\n",
        "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
        "    tf.keras.layers.Dense(33, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB54y33K5MMo",
        "outputId": "0219d5ad-819a-4377-90a6-e7504497c165"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 33)                2145      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,449\n",
            "Trainable params: 396,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YRDT3llC6o7S"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Train the Classification Model"
      ],
      "metadata": {
        "id": "N5BetCM6NK5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, verbose=1, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WflzBZsb6FfF",
        "outputId": "aed81e81-a984-49e5-9428-cdc2863c44ec"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "18/18 [==============================] - 13s 129ms/step - loss: 3.0575 - accuracy: 0.1311\n",
            "Epoch 2/25\n",
            "18/18 [==============================] - 2s 132ms/step - loss: 2.4654 - accuracy: 0.2543\n",
            "Epoch 3/25\n",
            "18/18 [==============================] - 2s 111ms/step - loss: 1.6433 - accuracy: 0.5234\n",
            "Epoch 4/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 1.0784 - accuracy: 0.7057\n",
            "Epoch 5/25\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 0.7421 - accuracy: 0.7891\n",
            "Epoch 6/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.5462 - accuracy: 0.8464\n",
            "Epoch 7/25\n",
            "18/18 [==============================] - 1s 78ms/step - loss: 0.3801 - accuracy: 0.8950\n",
            "Epoch 8/25\n",
            "18/18 [==============================] - 1s 78ms/step - loss: 0.3081 - accuracy: 0.9123\n",
            "Epoch 9/25\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.2685 - accuracy: 0.9253\n",
            "Epoch 10/25\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.2335 - accuracy: 0.9358\n",
            "Epoch 11/25\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 0.2160 - accuracy: 0.9410\n",
            "Epoch 12/25\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.2114 - accuracy: 0.9401\n",
            "Epoch 13/25\n",
            "18/18 [==============================] - 1s 82ms/step - loss: 0.1974 - accuracy: 0.9462\n",
            "Epoch 14/25\n",
            "18/18 [==============================] - 1s 78ms/step - loss: 0.1932 - accuracy: 0.9470\n",
            "Epoch 15/25\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 0.1922 - accuracy: 0.9470\n",
            "Epoch 16/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.1915 - accuracy: 0.9470\n",
            "Epoch 17/25\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.1912 - accuracy: 0.9470\n",
            "Epoch 18/25\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 0.1910 - accuracy: 0.9470\n",
            "Epoch 19/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.1908 - accuracy: 0.9470\n",
            "Epoch 20/25\n",
            "18/18 [==============================] - 1s 77ms/step - loss: 0.1906 - accuracy: 0.9470\n",
            "Epoch 21/25\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 0.1904 - accuracy: 0.9470\n",
            "Epoch 22/25\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 0.1903 - accuracy: 0.9470\n",
            "Epoch 23/25\n",
            "18/18 [==============================] - 1s 78ms/step - loss: 0.1901 - accuracy: 0.9470\n",
            "Epoch 24/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.1900 - accuracy: 0.9470\n",
            "Epoch 25/25\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 0.1899 - accuracy: 0.9470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANALYSE MODEL PERFORMANCE"
      ],
      "metadata": {
        "id": "QVi0rKUHNZzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keFMmeuM7QEV",
        "outputId": "b4680dd8-1b3a-4823-ba61-9ac084dd8419"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history_dict['accuracy']\n",
        "loss = history_dict['loss']"
      ],
      "metadata": {
        "id": "odZU4xbf9JKz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(\"Test accuracy: \", test_accuracy)\n",
        "print(\"Loss: \", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IVvJewc5gIs",
        "outputId": "7e85c782-5891-40cd-9404-ab8a38ca3eed"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 21ms/step - loss: 2.4494 - accuracy: 0.7109\n",
            "Test accuracy:  0.7109375\n",
            "Loss:  2.449390411376953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, acc, 'bo', label='Acc')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Loss')\n",
        "plt.title('Training and validation Acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "JOkyE_LV7YJf",
        "outputId": "d02f0248-db57-4b67-d7a4-79196a5d56d4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. An End-To-End Classification Model\n",
        "\n",
        "Pay attention that the above model is expected to receive batches of integer tensors as input:\n",
        "\n",
        "```\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " input_3 (InputLayer)        [(None, 50)]              0         \n",
        "```\n",
        "Thus, you can NOT supply raw data (some text) to the model for prediction. TensorFlow/Keras would generate error message as below:\n",
        "\n"
      ],
      "metadata": {
        "id": "sEyUxGi9Nw6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, sometimes it a big advantage if we can design a model which accepts raw data as input, then, process the data by itself.\n",
        "\n",
        "For example such a model can be easily exported different platforms/environments without the need of exporting the preprocess code!\n",
        "\n",
        "Therefore, Keras provides [several Preprocessing Layers](https://keras.io/api/layers/preprocessing_layers/) so that we can integrate preprocessing logic as a layer into a Keras model.\n",
        "\n",
        "After then, we can export such models and use any other platforms without re-writing preprocessing code on the exported platforms/environments.\n",
        "\n",
        "This kind of models can be called **End-To-End Models**. That is, an **End-To-End model** can accept Raw Input Data and preprocess it by itself.\n",
        "\n",
        "**What could be Raw Data? **\n",
        "\n",
        "It could be:\n",
        "* text\n",
        "* image\n",
        "* structure data\n",
        "* etc.\n",
        "\n",
        "Let's create an **End-To-End Classification Model** by integrating the **adapted** Keras `TextVectorization` layer into the **trained model** as **the first layer**. "
      ],
      "metadata": {
        "id": "HCAOqdjhN2Nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can create an **End-To-End Model** either by:\n",
        "* Keras Sequential API, or\n",
        "* Keras Functional API "
      ],
      "metadata": {
        "id": "eEXvGdLYN44T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.1. Create an End-To-End Model with Keras Sequential API"
      ],
      "metadata": {
        "id": "4z49-a1jNtha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "NbjxmMnXOQpZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_to_end_model = tf.keras.Sequential([\n",
        "  keras.Input(shape=(1,), dtype=\"string\"),\n",
        "  vectorize_layer,\n",
        "  model,\n",
        "  layers.Activation('softmax')\n",
        "])\n",
        "\n",
        "end_to_end_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "end_to_end_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHKp6z6B7aMy",
        "outputId": "1a28751b-14b1-4fb6-b32c-d2730bf96434"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 33)                396449    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 33)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,449\n",
            "Trainable params: 396,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.3. Test the End-to-End model with Raw (Text) Data"
      ],
      "metadata": {
        "id": "BbZsDqBEOjRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I extremely angry and sad in my relationships. I am hurting friendships. How I fix underlying issues?']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wmnv_i-Og4D",
        "outputId": "e266c943-95e5-4ec8-db99-cd42a9beaee1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anger Management\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAc0uJmpQSgb",
        "outputId": "440b37cf-2c19-4686-ded7-b599012b7080"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02880604, 0.02880604, 0.0781505 , 0.02880604, 0.02880663,\n",
              "        0.02880604, 0.02880604, 0.0288061 , 0.02880695, 0.02880604,\n",
              "        0.0288127 , 0.02880608, 0.02880604, 0.02880604, 0.02880606,\n",
              "        0.02880715, 0.02880605, 0.02880605, 0.02880604, 0.02880605,\n",
              "        0.02880604, 0.02880605, 0.02880817, 0.02880605, 0.02880604,\n",
              "        0.02880604, 0.02880604, 0.02883784, 0.02880604, 0.02880613,\n",
              "        0.02880633, 0.02881851, 0.02880604]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I am facing some issues with my friends in the college. They dont help me with studies. I am constantly alone. I am worried about my future. I cannot create bond with people. What could be the issue with me?']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLZfMxnUPCx5",
        "outputId": "10d828c3-4d75-4a32-f694-718703b694c5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trauma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX965mmYQUcC",
        "outputId": "00535dbf-30aa-4b82-8853-e3a6b8a702cf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02920806, 0.02920634, 0.02918994, 0.02918994, 0.02918994,\n",
              "        0.02918994, 0.02918994, 0.02918994, 0.02919044, 0.02918994,\n",
              "        0.03168174, 0.02918994, 0.02936126, 0.04037186, 0.02918994,\n",
              "        0.02919067, 0.02918994, 0.02949519, 0.02918994, 0.02918994,\n",
              "        0.02919054, 0.02918994, 0.02918994, 0.02918994, 0.02918996,\n",
              "        0.02918994, 0.02919008, 0.02918994, 0.02918995, 0.02944596,\n",
              "        0.05146669, 0.02920222, 0.02918999]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I just gone through abortion. It is hurting me as hell. I do not want to live anymore.']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktTyom51PnGM",
        "outputId": "26ed73dd-23cb-455e-b1ef-600f7091ea1b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anxiety\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgoZ9XFiQVRx",
        "outputId": "f324f4cf-4f21-46ed-bba2-fad44ed232ee"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02880667, 0.02880667, 0.02880667, 0.07811753, 0.02881899,\n",
              "        0.02880667, 0.0288067 , 0.02880667, 0.02882985, 0.02880667,\n",
              "        0.02880667, 0.02880667, 0.02882581, 0.02880901, 0.02880667,\n",
              "        0.02880669, 0.02880667, 0.02880693, 0.02880668, 0.02880667,\n",
              "        0.02880667, 0.02880667, 0.02880672, 0.02881529, 0.0288091 ,\n",
              "        0.02880667, 0.02880667, 0.02880667, 0.02880667, 0.02880667,\n",
              "        0.02880674, 0.02880668, 0.02880716]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I am very competitive. I am always on the top of the game. But, recently I am facing performance issues. I am constantly worried about my sport. I play good yet, not able to win matches.']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK6FDuGRP2V6",
        "outputId": "e70d4d00-01da-4a4b-959f-b638b03b030c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Family Conflict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "939MMNG7QVx0",
        "outputId": "9dff668e-af7f-4566-b085-5d75988c9cea"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02880432, 0.02880431, 0.02880431, 0.02880432, 0.02880431,\n",
              "        0.02880431, 0.02880431, 0.02880431, 0.02882068, 0.02880431,\n",
              "        0.02880431, 0.02880431, 0.07824111, 0.02880452, 0.02880431,\n",
              "        0.02880431, 0.02880431, 0.02880822, 0.02880431, 0.02880431,\n",
              "        0.02880444, 0.02880431, 0.02880431, 0.02880456, 0.02880438,\n",
              "        0.02880431, 0.02880431, 0.02880431, 0.02880431, 0.02880431,\n",
              "        0.02880435, 0.02880431, 0.02880431]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['My wife and I fight everyday. Cause could be a small reason. She is having lot of office work. I am not able to spend time with her. How can we solve the problem?']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55luKdd-QJjt",
        "outputId": "cc15b4dc-b12d-4906-9c48-913eeb743bfb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relationships\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbIs1lUcQ1me",
        "outputId": "80d11227-fd68-4455-84c5-0d74bf70f953"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 ,\n",
              "        0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 ,\n",
              "        0.0288033 , 0.0288033 , 0.02880334, 0.0288033 , 0.02880334,\n",
              "        0.0288033 , 0.0288033 , 0.0288033 , 0.02880385, 0.0288033 ,\n",
              "        0.0288033 , 0.0288033 , 0.0288033 , 0.07829378, 0.0288033 ,\n",
              "        0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 , 0.0288033 ,\n",
              "        0.0288033 , 0.0288033 , 0.0288033 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I went through sexual abuse in my childhood. It is constantly in my head. I cannot forget it. What should I do?']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aZlYmJmQ4-L",
        "outputId": "7b7b3ac1-e879-40c2-9f36-6ee4c06ed56e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Family Conflict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N214TWaARI1b",
        "outputId": "7641280e-bd11-489b-bba5-af0e3a3998ad"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02888212, 0.02888195, 0.02888195, 0.02888234, 0.02888198,\n",
              "        0.02888195, 0.02888195, 0.02888195, 0.02888198, 0.02888195,\n",
              "        0.02888218, 0.02888195, 0.07406063, 0.02888205, 0.02888433,\n",
              "        0.02888196, 0.02890733, 0.02921734, 0.02888414, 0.02888195,\n",
              "        0.02888196, 0.02888204, 0.02888195, 0.03022246, 0.02888198,\n",
              "        0.02888195, 0.02888236, 0.02888195, 0.02888195, 0.02888195,\n",
              "        0.02888878, 0.02888196, 0.02888469]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data=['I have put on lot of weight. I am really embarrassed and shameful to wear big clothes. How can I reduce my thoughts? ']\n",
        "predictions=end_to_end_model.predict(raw_data)\n",
        "print(id_to_topics[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5PXCsNARMYs",
        "outputId": "dce34944-16b3-4b70-a021-0cdd3aa28308"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anxiety\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X2zv6BERssJ",
        "outputId": "900a4e8c-0d02-40c2-d0f3-57f4cbacb5a2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02894841, 0.02894838, 0.0289486 , 0.07035195, 0.02960369,\n",
              "        0.02894838, 0.02894871, 0.02894838, 0.03033829, 0.02894838,\n",
              "        0.02894838, 0.02894838, 0.02895544, 0.02894984, 0.02894841,\n",
              "        0.02902098, 0.02894839, 0.0289488 , 0.02894933, 0.02894913,\n",
              "        0.02894838, 0.02894838, 0.02906435, 0.02898319, 0.02996771,\n",
              "        0.02894838, 0.02894845, 0.02894838, 0.02894838, 0.0289484 ,\n",
              "        0.02894857, 0.02894863, 0.02894855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = end_to_end_model.evaluate(test_features,test_targets)\n",
        "print(\"end_to_end_model accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6esUqx2WBSE",
        "outputId": "d5bfb422-59ea-4ed4-b36d-9e91468f75c4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 23ms/step - loss: 2.8416 - accuracy: 0.7104\n",
            "end_to_end_model accuracy:  0.7104377150535583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.4. Save the End-to-End model"
      ],
      "metadata": {
        "id": "DRosiMa0Wdiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "end_to_end_model.save(\"end_to_end_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANO22LHUWc6F",
        "outputId": "9394452e-051e-47fb-9bf8-2db2a790f024"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: end_to_end_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: end_to_end_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f51d271be90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f51f15a3190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.5. Load the End-to-End model"
      ],
      "metadata": {
        "id": "R-WHwXw4WitC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_end_to_end_model = tf.keras.models.load_model(\"end_to_end_model\")"
      ],
      "metadata": {
        "id": "wGZZE2obWgQ-"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.6. Test the Loaded End-to-End model with Raw (Text) Data"
      ],
      "metadata": {
        "id": "V01l042fWs5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = loaded_end_to_end_model.evaluate(test_features,test_targets)\n",
        "print(\"loaded_end_to_end_model accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWBn_qnUWoJ2",
        "outputId": "d2f38ae1-b274-48f5-b2ac-3af7e31a7ad5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 28ms/step - loss: 2.8416 - accuracy: 0.7104\n",
            "loaded_end_to_end_model accuracy:  0.7104377150535583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SUMMARY**\n",
        "WHAT WE HAVE WORKED ON ABOVE\n",
        "* What a Keras `TextVectorization` layer is\n",
        "* Why we need to use a Keras `TextVectorization` layer in Natural Languge Processing (NLP) tasks\n",
        "* How to employ a Keras `TextVectorization` layer in Text Preprocessing\n",
        "* How to integrate a Keras `TextVectorization` layer to a trained model\n",
        "* How to save and upload a Keras `TextVectorization` layer and a model with a Keras `TextVectorization` layer\n",
        "* How to integrate a Keras `TextVectorization` layer with TensorFlow Data Pipeline API (`tf.data`)\n",
        "* How to design, train, save, and load an End-to-End model using Keras `TextVectorization` layer\n",
        "\n",
        "All above topics are presented in a **multi-class text classification** context."
      ],
      "metadata": {
        "id": "kVXBcYTiW15r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c_CUHIG7Wxvk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}